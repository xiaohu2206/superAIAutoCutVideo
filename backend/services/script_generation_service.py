#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è„šæœ¬ç”Ÿæˆä¸šåŠ¡æœåŠ¡ï¼ˆä¸è·¯ç”±åˆ†ç¦»ï¼‰
èŒè´£ï¼š
- åŸºäºå­—å¹•srtæ–‡æœ¬è°ƒç”¨AIç”Ÿæˆå‰§æƒ…çˆ†ç‚¹åˆ†æï¼ˆplot_analysisï¼‰
- åŸºäº plot_analysis + å­—å¹• è°ƒç”¨æç¤ºè¯æ¨¡å—ç”Ÿæˆæ ¼å¼åŒ–è„šæœ¬æ–‡æ¡ˆï¼ˆJSONï¼‰
- æ¸…æ´—ä¸æ ¡éªŒæ ¼å¼åŒ–JSONï¼Œå¹¶è½¬æ¢ä¸ºå‰ç«¯VideoScriptç»“æ„

æœ¬æ¨¡å—ä¸è´Ÿè´£æŒä¹…åŒ–å­˜å‚¨ï¼Œç”±è·¯ç”±å±‚è°ƒç”¨ä¿å­˜ã€‚
"""

from __future__ import annotations

import logging
import math
import re
from datetime import datetime
from dataclasses import dataclass
from typing import Any, Dict, List, Tuple, Optional, cast
import asyncio
import json

from modules.ai import ChatMessage
from modules.prompts.prompt_manager import prompt_manager
from services.ai_service import ai_service
from modules.json_sanitizer import sanitize_json_text_to_dict, validate_script_items
from modules.projects_store import projects_store
from fastapi import HTTPException

logger = logging.getLogger(__name__)

DEFAULT_SCRIPT_LENGTH_SELECTION = "30ï½40æ¡"
SCRIPT_LENGTH_PRESETS: Dict[str, Tuple[int, int, int]] = {
    "15ï½20æ¡": (15, 20, 1),
    "30ï½40æ¡": (30, 40, 2),
    "40ï½60æ¡": (40, 60, 3),
    "60ï½80æ¡": (60, 80, 4),
    "80ï½100æ¡": (80, 100, 5),
}
MAX_SUBTITLE_ITEMS_PER_CALL = 2000
SOFT_INPUT_FACTOR = 1.8
MAX_SUBTITLE_CHARS_PER_CALL = 20000


@dataclass(frozen=True)
class ScriptTargetPlan:
    normalized_selection: str
    target_min: int
    target_max: int
    preferred_calls: int
    final_target_count: int


def normalize_script_length_selection(value: Optional[str]) -> Optional[str]:
    if value is None:
        return None
    v = str(value).strip()
    if not v:
        return None
    v = (
        v.replace(" ", "")
        .replace("~", "ï½")
        .replace("-", "ï½")
        .replace("â€”", "ï½")
        .replace("â€“", "ï½")
    )
    if not v.endswith("æ¡") and re.search(r"\d", v):
        v = v + "æ¡"
    if v in SCRIPT_LENGTH_PRESETS:
        return v
    m = re.search(r"(\d+)\D+(\d+)", v)
    if m:
        a = int(m.group(1))
        b = int(m.group(2))
        key = f"{a}ï½{b}æ¡"
        if key in SCRIPT_LENGTH_PRESETS:
            return key
    allowed = " | ".join(SCRIPT_LENGTH_PRESETS.keys())
    raise ValueError(f"script_length æ— æ•ˆï¼Œå¯é€‰å€¼: {allowed}")


def parse_script_length_selection(value: Optional[str]) -> ScriptTargetPlan:
    try:
        normalized = normalize_script_length_selection(value) or DEFAULT_SCRIPT_LENGTH_SELECTION
    except ValueError:
        normalized = DEFAULT_SCRIPT_LENGTH_SELECTION
    if normalized not in SCRIPT_LENGTH_PRESETS:
        normalized = DEFAULT_SCRIPT_LENGTH_SELECTION
    target_min, target_max, calls = SCRIPT_LENGTH_PRESETS[normalized]
    final_target_count = int(target_max)
    return ScriptTargetPlan(
        normalized_selection=normalized,
        target_min=int(target_min),
        target_max=int(target_max),
        preferred_calls=int(calls),
        final_target_count=final_target_count,
    )


def _split_subtitles_if_oversize(
    subtitles: List[Dict[str, Any]],
    max_items: int,
    soft_factor: float,
) -> List[List[Dict[str, Any]]]:
    soft_max = int(math.ceil(float(max_items) * float(soft_factor)))
    if soft_max <= 0 or len(subtitles) <= soft_max:
        return [subtitles]
    mid = len(subtitles) // 2
    if mid <= 0:
        return [subtitles[:soft_max]]
    left = subtitles[:mid]
    right = subtitles[mid:]
    out: List[List[Dict[str, Any]]] = []
    out.extend(_split_subtitles_if_oversize(left, max_items, soft_factor))
    out.extend(_split_subtitles_if_oversize(right, max_items, soft_factor))
    return [c for c in out if c]


def compute_subtitle_chunks(
    subtitles: List[Dict[str, Any]],
    desired_calls: int,
    max_items: int,
    soft_factor: float,
) -> List[Dict[str, Any]]:
    n = len(subtitles)
    if n <= 0:
        return []
    soft_max = int(math.ceil(float(max_items) * float(soft_factor)))
    min_calls = max(1, int(math.ceil(n / soft_max))) if soft_max > 0 else 1
    calls = max(1, int(desired_calls or 1), min_calls)
    base_slices: List[List[Dict[str, Any]]] = []
    for i in range(calls):
        start = (i * n) // calls
        end = ((i + 1) * n) // calls
        ch = subtitles[start:end]
        if ch:
            base_slices.append(ch)
    split_slices: List[List[Dict[str, Any]]] = []
    for ch in base_slices:
        split_slices.extend(_split_subtitles_if_oversize(ch, max_items, soft_factor))
    chunks: List[Dict[str, Any]] = []
    for idx, ch in enumerate(split_slices):
        try:
            start_s = float(ch[0].get("start") or 0.0)
            end_s = float(ch[-1].get("end") or start_s)
        except Exception:
            start_s = 0.0
            end_s = 0.0
        chunks.append(
            {
                "idx": idx,
                "start": start_s,
                "end": end_s,
                "subs": ch,
            }
        )
    return chunks


def allocate_output_counts(total_target_count: int, chunk_count: int) -> List[int]:
    t = int(total_target_count or 0)
    c = int(chunk_count or 0)
    if c <= 0:
        return []
    if t <= 0:
        return [1] * c
    if c <= t:
        base = t // c
        rem = t % c
        out = [base + 1 if i < rem else base for i in range(c)]
        return [max(1, int(x)) for x in out]
    return [1] * c


def _parse_timestamp_pair(ts_range: str) -> Tuple[float, float]:
    """å°† "HH:MM:SS,mmm-HH:MM:SS,mmm" è§£æä¸ºç§’æ•°å¯¹"""

    def _to_seconds(ts: str) -> float:
        h, m, rest = ts.split(":")
        s, ms = rest.split(",")
        return int(h) * 3600 + int(m) * 60 + int(s) + int(ms) / 1000.0

    parts = re.split(r"\s*[-â€“]\s*", ts_range.strip())
    if len(parts) != 2:
        raise ValueError(f"æ—¶é—´æˆ³èŒƒå›´æ ¼å¼é”™è¯¯: {ts_range}")
    return _to_seconds(parts[0]), _to_seconds(parts[1])


def _format_timestamp(s: float) -> str:
    total_ms = int(round(s * 1000))
    ms = total_ms % 1000
    total_sec = total_ms // 1000
    h = total_sec // 3600
    m = (total_sec % 3600) // 60
    sec = total_sec % 60
    return f"{h:02d}:{m:02d}:{sec:02d},{ms:03d}"


def _format_timestamp_range(start_s: float, end_s: float) -> str:
    return _format_timestamp(start_s) + "-" + _format_timestamp(end_s)


class ScriptGenerationService:
    """çŸ­å‰§è„šæœ¬æ–‡æ¡ˆç”ŸæˆæœåŠ¡"""

    @staticmethod
    async def generate_plot_analysis(subtitle_content: str) -> str:
        """
        è°ƒç”¨æ¨¡å‹ç”Ÿæˆçˆ†ç‚¹åˆ†ææå–ï¼ˆplot_analysisï¼‰ã€‚
        ä½¿ç”¨æŒ‡å®šç³»ç»Ÿæç¤ºè¯ï¼š
        "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å‰§æœ¬åˆ†æå¸ˆå’Œå‰§æƒ…æ¦‚æ‹¬åŠ©æ‰‹ã€‚è¯·ä»”ç»†åˆ†æå­—å¹•å†…å®¹ï¼Œæå–å…³é”®å‰§æƒ…ä¿¡æ¯ã€‚"
        """
        system_prompt = (
            "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å‰§æœ¬åˆ†æå¸ˆå’Œå‰§æƒ…æ¦‚æ‹¬åŠ©æ‰‹ã€‚è¯·ä»”ç»†åˆ†æå­—å¹•å†…å®¹ï¼Œæå–å…³é”®å‰§æƒ…ä¿¡æ¯ã€‚"
        )
        messages = [
            ChatMessage(role="system", content=system_prompt),
            ChatMessage(
                role="user",
                content=(
                    "è¯·åˆ†æä»¥ä¸‹å­—å¹•å†…å®¹ï¼Œæå–å…³é”®å‰§æƒ…ä¿¡æ¯ä¸çˆ†ç‚¹ï¼ˆåŒ…å«æ—¶é—´èŠ‚ç‚¹çš„è¦ç‚¹åˆ—è¡¨ï¼‰ï¼š\n\n"
                    + subtitle_content
                ),
            ),
        ]
        resp = await ai_service.send_chat(messages)
        return str(resp.content)

    @staticmethod
    def _chunk_text(
        text: str,
        chunk_chars_max: int = 15000,
        overlap_ratio: float = 0.12,
        min_last_ratio: float = 0.4,
    ) -> List[str]:
        text = str(text or "").strip()
        if not text:
            return []
        max_len = max(1000, int(chunk_chars_max))
        overlap = max(0, int(max_len * overlap_ratio))
        chunks: List[str] = []
        i = 0
        n = len(text)
        while i < n:
            end = min(n, i + max_len)
            cand = text[i:end]
            cut = len(cand)
            for sep in ["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ"]:
                pos = cand.rfind(sep)
                if pos >= int(max_len * 0.6):
                    cut = pos + len(sep)
                    break
            chunk = cand[:cut]
            chunks.append(chunk)
            if end >= n:
                break
            i = i + cut - overlap if overlap > 0 else i + cut
            if i < 0:
                i = 0
        if len(chunks) >= 2:
            last_len = len(chunks[-1])
            if last_len < int(max_len * min_last_ratio):
                prev = chunks[-2]
                needed = int(max_len * min_last_ratio) - last_len
                movable = min(needed, int(max_len * 0.5), max(0, len(prev) // 2))
                start_region = max(0, len(prev) - movable - int(max_len * 0.1))
                cut_pos = max(start_region, len(prev) - movable)
                for sep in ["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ"]:
                    pos = prev.rfind(sep, start_region)
                    if pos != -1:
                        cut_pos = pos + len(sep)
                        break
                move = prev[cut_pos:]
                chunks[-2] = prev[:cut_pos]
                chunks[-1] = move + chunks[-1]
                if len(chunks[-2]) == 0:
                    merged = chunks[-1]
                    chunks = chunks[:-2]
                    chunks.append(merged)
        return chunks

    @staticmethod
    async def _extract_plot_points_for_chunk(
        subtitle_chunk: str,
        chunk_id: int,
        max_points: int = 12,
    ) -> List[Dict[str, Any]]:
        sys_prompt = (
            "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å‰§æœ¬åˆ†æå¸ˆã€‚è¯·åŸºäºæä¾›çš„å­—å¹•ç‰‡æ®µï¼Œæå–åŒ…å«æ—¶é—´èŒƒå›´çš„å…³é”®å‰§æƒ…çˆ†ç‚¹ï¼Œä¸¥æ ¼è¾“å‡ºJSONã€‚"
        )
        fmt_lines = [
            "JSONæ ¼å¼:",
            "{",
            '  "plot_points": [',
            "    {",
            '      "timestamp": "HH:MM:SS,mmm-HH:MM:SS,mmm",',
            '      "title": "...",',
            '      "summary": "...",',
            '      "keywords": ["..."],',
            '      "confidence": 0.0',
            "    }",
            "  ]",
            "}",
            "",
        ]
        head = (
            "è¯·ä»ä»¥ä¸‹å­—å¹•ç‰‡æ®µä¸­æå–ä¸è¶…è¿‡"
            + str(max_points)
            + "æ¡å…³é”®å‰§æƒ…çˆ†ç‚¹ï¼Œä¸¥æ ¼è¾“å‡ºJSONå¯¹è±¡ï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡å­—ã€‚"
        )
        user_prompt = (
            head
            + "\n\n"
            + "\n".join(fmt_lines)
            + "\nå­—å¹•ç‰‡æ®µ:\n\n"
            + subtitle_chunk
        )
        messages = [
            ChatMessage(role="system", content=sys_prompt),
            ChatMessage(role="user", content=user_prompt),
        ]
        resp = await ai_service.send_chat(messages, response_format={"type": "json_object"})
        data, _raw = sanitize_json_text_to_dict(resp.content)
        items = data.get("plot_points") or []
        if not isinstance(items, list):
            items = []
        out: List[Dict[str, Any]] = []
        for idx, it in enumerate(items):
            if not isinstance(it, dict):
                continue
            ts = it.get("timestamp")
            title = it.get("title")
            summary = it.get("summary")
            keywords = it.get("keywords")
            conf = it.get("confidence")
            if not ts or not title:
                continue
            try:
                _parse_timestamp_pair(str(ts))
            except Exception:
                continue
            out.append({
                "timestamp": str(ts),
                "title": str(title),
                "summary": str(summary or ""),
                "keywords": [str(k) for k in (keywords or []) if k],
                "confidence": float(conf) if isinstance(conf, (int, float)) else 0.5,
                "chunk_id": int(chunk_id),
                "local_rank": idx + 1,
            })
        return out

    @staticmethod
    def _normalize_title(s: str) -> str:
        return re.sub(r"\s+", "", str(s or "").lower())

    @staticmethod
    def _merge_plot_points(
        points: List[Dict[str, Any]],
        similarity_threshold: float = 0.6,
        time_merge_threshold_ms: int = 30000,
    ) -> List[Dict[str, Any]]:
        def _ms_pair(ts: str) -> Tuple[int, int]:
            a, b = _parse_timestamp_pair(ts)
            return int(a * 1000), int(b * 1000)
        merged: List[Dict[str, Any]] = []
        for pt in points:
            ts = str(pt.get("timestamp"))
            title = str(pt.get("title"))
            s_ms, e_ms = _ms_pair(ts)
            found = False
            for mp in merged:
                ms, me = _ms_pair(str(mp["timestamp"]))
                ov = min(e_ms, me) - max(s_ms, ms)
                near = max(0, max(s_ms, ms) - min(e_ms, me)) <= time_merge_threshold_ms
                title_sim = 1.0 if ScriptGenerationService._normalize_title(title) == ScriptGenerationService._normalize_title(mp["title"]) else 0.0
                if (ov > 0 or near) and title_sim >= similarity_threshold:
                    mp["summary"] = (
                        mp.get("summary", "")
                        if len(str(mp.get("summary", "")))
                        >= len(str(pt.get("summary", "")))
                        else str(pt.get("summary", ""))
                    )
                    mp["keywords"] = list({*(mp.get("keywords") or []), *(pt.get("keywords") or [])})
                    mp["confidence"] = (
                        float(mp.get("confidence", 0.5))
                        + float(pt.get("confidence", 0.5))
                    ) / 2.0
                    found = True
                    break
            if not found:
                merged.append(pt)
        merged.sort(key=lambda x: _parse_timestamp_pair(str(x["timestamp"]))[0])
        return merged

    @staticmethod
    def _compose_plot_analysis_text(points: List[Dict[str, Any]]) -> str:
        lines: List[str] = []
        for i, pt in enumerate(points, start=1):
            ts = str(pt.get("timestamp"))
            title = str(pt.get("title"))
            summary = str(pt.get("summary", ""))
            kws = ",".join([str(k) for k in (pt.get("keywords") or [])])
            line = (
                "çˆ†ç‚¹{}ï¼š{}\n".format(i, title)
                + "æ—¶é—´ï¼š{}\n".format(ts)
                + "æ‘˜è¦ï¼š{}\n".format(summary)
                + "å…³é”®è¯ï¼š{}\n".format(kws)
            )
            lines.append(line)
        return "\n".join(lines).strip()

    @staticmethod
    async def generate_plot_analysis_pipeline(
        subtitle_content: str,
        chunk_chars_max: int = 15000,
        overlap_ratio: float = 0.12,
        max_points_per_chunk: int = 20,
    ) -> str:
        chunks = ScriptGenerationService._chunk_text(
            subtitle_content,
            chunk_chars_max,
            overlap_ratio,
        )
        all_points: List[Dict[str, Any]] = []
        sem = asyncio.Semaphore(4)

        async def run_one(i: int, ch: str) -> List[Dict[str, Any]]:
            async with sem:
                try:
                    return await ScriptGenerationService._extract_plot_points_for_chunk(
                        ch,
                        i,
                        max_points_per_chunk,
                    )
                except Exception:
                    return []
        tasks = [run_one(idx, ch) for idx, ch in enumerate(chunks)]
        results = await asyncio.gather(*tasks)
        for pts in results:
            if pts:
                all_points.extend(pts)
        merged = ScriptGenerationService._merge_plot_points(all_points)
        return ScriptGenerationService._compose_plot_analysis_text(merged)

    @staticmethod
    def _parse_srt_subtitles(subtitle_content: str) -> List[Dict[str, Any]]:
        """è§£æå­—å¹•æ–‡æœ¬ä¸ºç»“æ„åŒ–åˆ—è¡¨ï¼Œæ”¯æŒæ ‡å‡†SRTä¸å‹ç¼©è¡Œå†…æ—¶é—´æˆ³æ ¼å¼"""
        subs: List[Dict[str, Any]] = []
        content = subtitle_content.strip().replace("\r\n", "\n").replace("\r", "\n")
        if content.startswith('"') and content.endswith('"'):
            content = content[1:-1]
        lines = [ln.strip() for ln in content.split("\n") if ln.strip()]

        bracket_pattern = re.compile(r"^\[(\d{2}:\d{2}:\d{2},\d{3})-(\d{2}:\d{2}:\d{2},\d{3})\]\s*(.+)$")
        bracket_matches = [bracket_pattern.match(ln) for ln in lines]
        if any(bracket_matches):
            idx = 1
            for m in bracket_matches:
                if not m:
                    continue
                start_str, end_str, text = m.groups()
                try:
                    start_s = ScriptGenerationService._parse_timestamp_str(start_str)
                    end_s = ScriptGenerationService._parse_timestamp_str(end_str)
                except Exception:
                    continue
                subs.append({
                    "index": idx,
                    "start": start_s,
                    "end": end_s,
                    "text": text.strip(),
                })
                idx += 1
            subs.sort(key=lambda s: (s["start"], s["end"]))
            return subs

        pattern = re.compile(r"(\d+)\s+(\d{2}:\d{2}:\d{2},\d{3})\s*-->\s*(\d{2}:\d{2}:\d{2},\d{3})\s+(.+?)(?=\n\s*\d+\s+\d{2}:\d{2}:\d{2}|\Z)", re.DOTALL)
        norm = content + "\n"
        matches = pattern.findall(norm)
        for m in matches:
            idx_str, start_str, end_str, text = m
            try:
                start_s = ScriptGenerationService._parse_timestamp_str(start_str)
                end_s = ScriptGenerationService._parse_timestamp_str(end_str)
            except Exception:
                continue
            subs.append({
                "index": int(idx_str),
                "start": start_s,
                "end": end_s,
                "text": text.strip(),
            })
        subs.sort(key=lambda s: (s["start"], s["end"]))
        return subs

    @staticmethod
    def _parse_timestamp_str(ts: str) -> float:
        """è§£æå•ä¸ªæ—¶é—´æˆ³ 00:00:00,000 ä¸ºç§’æ•°"""
        try:
            h, m, s = ts.replace(',', '.').split(':')
            return int(h) * 3600 + int(m) * 60 + float(s)
        except Exception:
            return 0.0

    @staticmethod
    def _filter_plot_analysis_by_time(plot_analysis: str, start_s: float, end_s: float) -> str:
        """ä»å‰§æƒ…åˆ†ææ–‡æœ¬ä¸­ç­›é€‰å‡ºå½“å‰æ—¶é—´çª—å£ç›¸å…³çš„çˆ†ç‚¹"""
        if not plot_analysis:
            return ""
        # å‡è®¾ plot_analysis æ˜¯ç”± _compose_plot_analysis_text ç”Ÿæˆçš„æ ¼å¼
        # çˆ†ç‚¹Xï¼šTitle
        # æ—¶é—´ï¼šHH:MM:SS,mmm-HH:MM:SS,mmm
        lines = plot_analysis.split('\n')
        relevant_lines: List[str] = []
        current_block: List[str] = []
        in_block = False
        block_time_range = None
        for line in lines:
            if line.startswith("çˆ†ç‚¹"):
                if current_block and block_time_range:
                    # æ£€æŸ¥ä¸Šä¸€å—æ˜¯å¦ç›¸å…³
                    bs, be = block_time_range
                    # ç®€å•çš„é‡å åˆ¤æ–­
                    if not (be < start_s or bs > end_s):
                        relevant_lines.extend(current_block)
                current_block = [line]
                in_block = True
                block_time_range = None
            elif line.startswith("æ—¶é—´ï¼š") and in_block:
                current_block.append(line)
                try:
                    ts_str = line.replace("æ—¶é—´ï¼š", "").strip()
                    block_time_range = _parse_timestamp_pair(ts_str)
                except Exception:
                    pass
            elif in_block:
                current_block.append(line)

        # å¤„ç†æœ€åä¸€å—
        if current_block and block_time_range:
            bs, be = block_time_range
            if not (be < start_s or bs > end_s):
                relevant_lines.extend(current_block)
        if not relevant_lines:
            # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ï¼Œä¸ºäº†ä¸Šä¸‹æ–‡ï¼Œè¿”å›å‰300ä¸ªå­—ç¬¦æˆ–æ‘˜è¦
            return plot_analysis[:500] + "..."
        return "\n".join(relevant_lines)

    @staticmethod
    def _clean_plot_analysis_for_prompt(text: str) -> str:
        if not text:
            return ""
        lines = [ln for ln in str(text).splitlines() if not re.match(r"^\s*(æ—¶é—´ï¼š|æ—¶é—´:|å…³é”®è¯ï¼š|å…³é”®è¯:)", ln)]
        out = "\n".join(lines)
        out = re.sub(r"\n{3,}", "\n\n", out).strip()
        return out

    @staticmethod
    def _default_prompt_key_for_project(project_id: Optional[str]) -> str:
        """æ ¹æ®é¡¹ç›®çš„è§£è¯´ç±»å‹é€‰æ‹©é»˜è®¤å®˜æ–¹æ¨¡æ¿é”®"""
        category = "short_drama_narration"
        if project_id:
            p = projects_store.get_project(project_id)
            if p:
                t = str(getattr(p, "narration_type", "") or "")
                if t == "ç”µå½±è§£è¯´":
                    category = "movie_narration"
                else:
                    category = "short_drama_narration"
        return f"{category}:script_generation"

    @staticmethod
    def _resolve_prompt_key(project_id: Optional[str], default_key: str) -> str:
        if not project_id:
            return default_key
        p = projects_store.get_project(project_id)
        if not p:
            return default_key
        sel_map = getattr(p, "prompt_selection", {}) or {}
        sel = sel_map.get(default_key)
        if not isinstance(sel, dict):
            return default_key
        t = str(sel.get("type") or "official").lower()
        kid = str(sel.get("key_or_id") or "")
        if t == "user" and kid:
            return kid.split(":", 1)[-1]
        if t == "official" and kid:
            return kid
        return default_key

    @staticmethod
    async def _generate_script_chunk(
        chunk_idx: int,
        chunk_total: int,
        start_time: float,
        end_time: float,
        subtitles: List[Dict[str, Any]],
        plot_analysis_snippet: str,
        drama_name: str,
        project_id: Optional[str] = None,
        target_items_count: Optional[int] = None,
    ) -> List[Dict[str, Any]]:
        subs_text_lines = []
        for s in subtitles:
            ts = _format_timestamp_range(float(s["start"]), float(s["end"]))
            subs_text_lines.append(f"[{ts}] {s['text']}")
        subs_text = "\n".join(subs_text_lines)
        if len(subs_text) > MAX_SUBTITLE_CHARS_PER_CALL:
            subs_text = subs_text[:MAX_SUBTITLE_CHARS_PER_CALL]
        default_key = ScriptGenerationService._default_prompt_key_for_project(project_id)
        key = ScriptGenerationService._resolve_prompt_key(project_id, default_key)
        variables = {
            "drama_name": drama_name,
            "plot_analysis": plot_analysis_snippet or "",
            "subtitle_content": subs_text,
        }
        try:
            messages_dicts = prompt_manager.build_chat_messages(key, variables)
        except KeyError:
            try:
                cat = (key.split(":", 1)[0] if ":" in key else "short_drama_narration")
                if cat == "movie_narration":
                    from modules.prompts.movie_narration import register_prompts
                else:
                    from modules.prompts.short_drama_narration import register_prompts
                register_prompts()
                messages_dicts = prompt_manager.build_chat_messages(key, variables)
            except Exception:
                key = default_key
                messages_dicts = prompt_manager.build_chat_messages(key, variables)
        messages = [ChatMessage(role=m["role"], content=m["content"]) for m in messages_dicts]
        
        logger.info(f"âš¡ æ­£åœ¨ç”Ÿæˆåˆ†æ®µ {int(chunk_idx)+1}/{chunk_total}...")

        if int(chunk_total or 0) > 0:
            total = int(chunk_total)
            idx = int(chunk_idx)
            if idx <= 0:
                pos_label = "å¼€å§‹æ®µ"
            elif idx >= total - 1:
                pos_label = "æœ«å°¾æ®µ"
            else:
                pos_label = "ä¸­é—´æ®µ"
            messages.insert(
                0,
                ChatMessage(
                    role="system",
                    content=(
                        f"è¿™æ˜¯åˆ†æ®µç”Ÿæˆè„šæœ¬çš„ç¬¬{idx + 1}æ®µ/å…±{total}æ®µï¼Œä½ç½®ä¸º{pos_label}ã€‚"
                        "å¼€å§‹ï¼ˆ1ï¼‰æ®µå¯å¼•å…¥å‰§æƒ…ï¼Œä¸­é—´æ®µä¸è¦é‡å¤å¼€åœºæˆ–æ”¶å°¾ï¼ˆå› ä¸ºéœ€è¦åˆå¹¶å…¶å®ƒæ®µè¿›æ¥ï¼‰ï¼Œæœ«å°¾æ®µéœ€è¦æ”¶æŸå‰§æƒ…å¹¶é¿å…æ–°å¼€å¤´ã€‚"
                    ),
                ),
            )
        if target_items_count and int(target_items_count) > 0:
            n = int(target_items_count)
            messages.insert(
                0,
                ChatMessage(
                    role="system",
                    content=(
                        f"ä½ å¿…é¡»ä»…è¾“å‡ºä¸€ä¸ªJSONå¯¹è±¡ï¼Œé”®ä¸º'items'ã€‚"
                        f"itemsæ•°ç»„é•¿åº¦å¿…é¡»ä¸¥æ ¼ç­‰äº{n}ï¼Œä¸èƒ½å¤šä¸èƒ½å°‘ã€‚"
                        f"start_timeå’Œend_timeæ—¶é—´é—´éš”ä¸èƒ½ä½äº1s"
                        f"æ¯æ¡å¿…é¡»åŒ…å«'_id','timestamp','picture','narration','OST'ã€‚"
                        f"ä¸å¾—è¾“å‡ºé™¤JSONä»¥å¤–çš„ä»»ä½•æ–‡å­—ã€‚"
                    ),
                ),
            )
        try:
            resp = await ai_service.send_chat(messages, response_format={"type": "json_object"})
            data, _ = sanitize_json_text_to_dict(resp.content)
            data = validate_script_items(data)
            items = data.get("items") or []
            logger.info(f"v{int(chunk_idx)+1} ç”Ÿæˆåˆ†æ®µ, å…±{len(items)}æ¡")
            valid_items: List[Dict[str, Any]] = []
            for it in items:
                try:
                    s_t, e_t = _parse_timestamp_pair(str(it.get("timestamp")))
                    if e_t < start_time - 5 or s_t > end_time + 5:
                        continue
                    valid_items.append(
                        {
                            "_id": it.get("_id"),
                            "timestamp": str(it.get("timestamp")),
                            "picture": it.get("picture"),
                            "narration": str(it.get("narration", "")),
                            "OST": 1 if it.get("OST") == 1 else 0,
                            "_chunk_idx": chunk_idx,
                        }
                    )
                except Exception:
                    continue
            if target_items_count and int(target_items_count) > 0:
                n = int(target_items_count)
                out: List[Dict[str, Any]] = []
                for it in valid_items:
                    if len(out) >= n:
                        break
                    out.append(it)
                if len(out) < n:
                    for it in items:
                        if len(out) >= n:
                            break
                        out.append(
                            {
                                "_id": it.get("_id"),
                                "timestamp": str(it.get("timestamp")),
                                "picture": it.get("picture"),
                                "narration": str(it.get("narration", "")),
                                "OST": 1 if it.get("OST") == 1 else 0,
                                "_chunk_idx": chunk_idx,
                            }
                        )
                return out
            return valid_items
        except Exception as e:
            logger.error(f"Chunk {chunk_idx} generation failed: {e}")
            return []

    @staticmethod
    def _merge_items(all_items: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        sorted_items = sorted(all_items, key=lambda x: _parse_timestamp_pair(str(x["timestamp"]))[0])
        merged: List[Dict[str, Any]] = []
        if not sorted_items:
            return []
        current = sorted_items[0]
        for next_it in sorted_items[1:]:
            try:
                cs, ce = _parse_timestamp_pair(str(current["timestamp"]))
                ns, ne = _parse_timestamp_pair(str(next_it["timestamp"]))
            except Exception:
                merged.append(current)
                current = next_it
                continue
            overlap_start = max(cs, ns)
            overlap_end = min(ce, ne)
            overlap_len = max(0.0, overlap_end - overlap_start)
            curr_len = max(0.0, ce - cs)
            next_len = max(0.0, ne - ns)
            if overlap_len > 0 and (overlap_len > 0.4 * min(curr_len, next_len) + 0.1):
                if len(str(next_it.get("narration", ""))) > len(str(current.get("narration", ""))):
                    current = next_it
                else:
                    pass
            else:
                merged.append(current)
                current = next_it
        merged.append(current)
        min_duration = 0.8
        filtered: List[Dict[str, Any]] = []
        for it in merged:
            try:
                s, e = _parse_timestamp_pair(str(it["timestamp"]))
                if max(0.0, e - s) < min_duration:
                    continue
            except Exception:
                pass
            filtered.append(it)
        for i, it in enumerate(filtered, start=1):
            it["_id"] = i
        return filtered

    @staticmethod
    async def _refine_full_script(
        segments: List[Dict[str, Any]],
        drama_name: str,
        plot_analysis: str,
        length_mode: Optional[str] = None,
        target_count: Optional[int] = None,
    ) -> List[Dict[str, Any]]:
        items = segments
        if not items:
            return []
        draft_str = json.dumps(items, ensure_ascii=False)
        n = len(items)
        if target_count and int(target_count) > 0:
            target = int(target_count)
        else:
            target = int(n)
        if target < 1:
            target = 1
        if target >= n:
            retain_desc = ""
        else:
            retain_desc = (
                f"å¿…é¡»ä»…ä¿ç•™ {target} æ¡æœ€å…³é”®æ¡ç›®ï¼Œå…¶ä½™å…¨éƒ¨åˆ é™¤ï¼ˆå¿…é¡»éµå®ˆï¼‰ã€‚"
                f"è¿”å›çš„ 'items' é•¿åº¦å¿…é¡»ä¸º {target}ï¼Œä¸å¾—æ–°å¢æ¡ç›®ï¼Œä»…åœ¨å·²æœ‰ '_id' ä¸­é€‰æ‹©ï¼Œä½†ä¸€å®šè¦ç¡®ä¿ä¸èƒ½çƒ‚å°¾ã€‚"
            )

        system_prompt = (
            "ä½ æ˜¯ä¸€ä½åˆ†å—è„šæœ¬åˆå¹¶åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†å·²æŒ‰æ—¶é—´åˆ†å—ç”Ÿæˆçš„è§£è¯´è„šæœ¬è¿›è¡Œè½»é‡åˆå¹¶ä¸é¡ºç•…è¡”æ¥ã€‚"
            + retain_desc +
            "**åŸå£°ä¸è§£è¯´æ¯”ä¾‹**ï¼š7:3ï¼ˆåŸå£°70%ï¼Œè§£è¯´30%ï¼‰"
            "**åŸå£°ç‰‡æ®µæ ‡è¯†**ï¼šOST=1è¡¨ç¤ºåŸå£°ï¼ŒOST=0è¡¨ç¤ºè§£è¯´"
            "å¯¹äºå•ä¸€æ¡ç›®ï¼Œä»…å¯¹éƒ¨åˆ†çš„ 'narration' è¿›è¡Œå°å¹…æ¶¦è‰²ï¼Œæ¯”å¦‚è¡¥å……å¿…è¦çš„è¿æ¥è¯ã€æ¶ˆé™¤é‡å¤æˆ–æ–­è£‚ï¼Œè®©ä¸Šä¸‹æ–‡è‡ªç„¶è¿è´¯ï¼›ä¸è¦æ”¹å˜åŸæœ‰ä¿¡æ¯ä¸å«ä¹‰ã€‚"
            "å¯¹äºæ‰€æœ‰è„šæœ¬å†…å®¹ï¼Œæ˜¯é€šè¿‡å¤šä¸ªæ¨¡å‹ç”Ÿæˆçš„ï¼Œæ¯ä¸ªæ¨¡å‹ç”Ÿæˆçš„è„šæœ¬æ®µå®¹æ˜“å‡ºç°å¼€å¤´è¯­å’Œç»“å°¾è¯­ï¼Œä½†å¯èƒ½æ˜¯ä¸­é—´æ®µï¼Œå¦‚æœæ˜¯ä¸­é—´æ®µåº”è¯¥æŠŠå¼€å¤´è¯­æˆ–ç»“å°¾è¯­æ¡ç›®åˆ é™¤"
            "å¯¹äºå•ä¸€æ¡ç›®ï¼Œä¸€èˆ¬ä¸ä¿®æ”¹ 'picture' ä¸ 'OST'ï¼Œå¦‚æ— å¿…è¦å˜æ›´åˆ™åŸæ ·è¿”å›ã€‚"
            "ä»…è¿”å›ä¸€ä¸ª JSON å¯¹è±¡ï¼Œé”®ä¸º 'items'ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« '_id', 'timestamp', 'picture', 'narration', 'OST'ï¼›ä¸è¦è¾“å‡ºé™¤ JSON ä»¥å¤–çš„ä»»ä½•å†…å®¹ã€‚"
        )
        user_content = (
            f"{retain_desc}\n\n"
            f"å‰§åï¼š{drama_name}\n"
            f"è‰ç¨¿ï¼š\n{draft_str}\n\n"
            # f"å‰§æƒ…èƒŒæ™¯ï¼š\n{ScriptGenerationService._clean_plot_analysis_for_prompt(plot_analysis)}\n\n"
            "è¯·æŒ‰è¦æ±‚è¿”å› JSONã€‚"
        )
        messages = [
            ChatMessage(role="system", content=system_prompt),
            ChatMessage(role="user", content=user_content)
        ]
        try:
            logger.info(f"âœ¨ æ­£åœ¨è¿›è¡Œå…¨å±€æ¶¦è‰²... (ç›®æ ‡æ¡æ•°: {target})")
            resp = await ai_service.send_chat(messages, response_format={"type": "json_object"})
            data, _ = sanitize_json_text_to_dict(resp.content)
            data = validate_script_items(data)
            llm_items = data.get("items", [])
            llm_ids_ordered: List[int] = []
            for it in llm_items:
                try:
                    if it.get("_id") is None:
                        continue
                    llm_ids_ordered.append(int(it.get("_id")))
                except Exception:
                    continue
            new_items_map = {int(it.get("_id")): it for it in llm_items if it.get("_id") is not None}

            def _update_item(orig: Dict[str, Any], new_it: Optional[Dict[str, Any]]) -> Dict[str, Any]:
                _id_val = int(orig.get("_id") or 0)
                if new_it:
                    orig["narration"] = str(new_it.get("narration", orig.get("narration", "")))
                    orig["picture"] = new_it.get("picture")
                    try:
                        ost_val = 1 if new_it.get("OST") == 1 else 0
                        orig["OST"] = ost_val
                    except Exception:
                        pass
                orig["_id"] = _id_val
                return orig

            if target >= n:
                final_items_all: List[Dict[str, Any]] = []
                for i, it in enumerate(items, start=1):
                    _id = int(it.get("_id") or i)
                    it["_id"] = _id
                    final_items_all.append(_update_item(it, new_items_map.get(_id)))
                return final_items_all

            keep_ids: List[int] = []
            if llm_ids_ordered:
                for _id in llm_ids_ordered:
                    if _id not in keep_ids:
                        keep_ids.append(_id)
                if len(keep_ids) > target:
                    keep_ids = keep_ids[:target]
            else:
                ids_all = [int(it.get("_id") or idx) for idx, it in enumerate(items, start=1)]
                keep_ids = ids_all[:target]

            id_set = set([int(it.get("_id") or idx) for idx, it in enumerate(items, start=1)])
            keep_ids = [i for i in keep_ids if i in id_set]
            if len(keep_ids) < target:
                for i in sorted(id_set):
                    if i not in keep_ids:
                        keep_ids.append(i)
                    if len(keep_ids) >= target:
                        break

            final_items_selected: List[Dict[str, Any]] = []
            for i, it in enumerate(items, start=1):
                _id = int(it.get("_id") or i)
                if _id in keep_ids:
                    it["_id"] = _id
                    final_items_selected.append(_update_item(it, new_items_map.get(_id)))
            return final_items_selected
        except Exception as e:
            logger.warning(f"Refine script failed, returning draft: {e}")
            return items

    @staticmethod
    async def generate_script_json(drama_name: str, plot_analysis: str, subtitle_content: str, project_id: Optional[str] = None) -> Dict[str, Any]:
        """
        ç”Ÿæˆè§£è¯´è„šæœ¬ï¼ˆMap-Reduce-Refine æ¨¡å¼ï¼‰
        1. è§£æå­—å¹•
        2. æŒ‰ç›®æ ‡æ¡æ•°è§„åˆ’è°ƒç”¨æ¬¡æ•°ï¼Œå¹¶æŒ‰å­—å¹•æ¡æ•°åˆ‡åˆ†å­ä»»åŠ¡ (Map)
        3. å¹¶å‘ç”Ÿæˆå„å­ä»»åŠ¡è„šæœ¬ï¼ˆæ¯æ¬¡å¼ºåˆ¶è¾“å‡ºæŒ‡å®šæ¡æ•°ï¼‰
        4. åˆå¹¶å»é‡ (Reduce)
        5. å…¨å±€æ¶¦è‰²å¹¶å¼ºåˆ¶è¾“å‡ºæœ€ç»ˆæ¡æ•° (Refine)
        """
        # 1. è§£æå­—å¹•
        subtitles = ScriptGenerationService._parse_srt_subtitles(subtitle_content)
        if not subtitles:
            logger.warning("Subtitle parsing failed")
            raise HTTPException(status_code=400, detail="å­—å¹•è§£æå¤±è´¥ï¼šè¯·ä¸Šä¼ æœ‰æ•ˆçš„SRTå­—å¹•æˆ–æ ‡å‡†æ—¶é—´æˆ³æ ¼å¼")
        total_duration = subtitles[-1]["end"] if subtitles else 0
        if total_duration == 0:
            logger.warning("Subtitle total duration invalid")
            raise HTTPException(status_code=400, detail="å­—å¹•è§£æå¤±è´¥ï¼šå­—å¹•æ—¶é—´æˆ³æ— æ•ˆ")

        sel_length: Optional[str] = None
        if project_id:
            try:
                p = projects_store.get_project(project_id)
                if p:
                    if getattr(p, "script_length", None):
                        sel_length = str(getattr(p, "script_length", None))
            except Exception:
                sel_length = None

        # Log model info for user visibility
        try:
            model_info = ai_service.get_provider_info()
            m_name = model_info.get("active_model", "Unknown")
            m_prov = model_info.get("active_provider", "Unknown")
            logger.info(f"ğŸš€ å¼€å§‹ç”Ÿæˆè„šæœ¬ | å‰§å: {drama_name} | æ¨¡å‹: {m_name} ({m_prov})")
        except Exception:
            logger.info(f"ğŸš€ å¼€å§‹ç”Ÿæˆè„šæœ¬ | å‰§å: {drama_name}")

        plan = parse_script_length_selection(sel_length)
        chunks = compute_subtitle_chunks(
            subtitles=subtitles,
            desired_calls=plan.preferred_calls,
            max_items=MAX_SUBTITLE_ITEMS_PER_CALL,
            soft_factor=SOFT_INPUT_FACTOR,
        )
        if not chunks:
            raise HTTPException(status_code=400, detail="å­—å¹•è§£æå¤±è´¥ï¼šå­—å¹•å†…å®¹ä¸ºç©º")

        logger.info(f"ğŸ“‹ æ‰§è¡Œè®¡åˆ’: å…± {len(chunks)} ä¸ªåˆ†æ®µä»»åŠ¡ | ç›®æ ‡æ€»æ¡æ•°: {plan.final_target_count}")
        per_call_counts = allocate_output_counts(plan.final_target_count, len(chunks))
        sem = asyncio.Semaphore(5)

        async def generate_one(chunk: Dict[str, Any]) -> List[Dict[str, Any]]:
            async with sem:
                local_plot = ScriptGenerationService._filter_plot_analysis_by_time(
                    plot_analysis, chunk["start"], chunk["end"]
                )
                return await ScriptGenerationService._generate_script_chunk(
                    chunk["idx"],
                    len(chunks),
                    chunk["start"],
                    chunk["end"],
                    chunk["subs"],
                    local_plot,
                    drama_name,
                    project_id,
                    per_call_counts[int(chunk["idx"])],
                )

        tasks = [generate_one(c) for c in chunks]
        results = await asyncio.gather(*tasks)
        all_items: List[Dict[str, Any]] = []
        for res in results:
            all_items.extend(res)
        merged_items = ScriptGenerationService._merge_items(all_items)
        effective_target = min(len(merged_items), int(plan.final_target_count))
        if len(chunks) <= 1:
            final_items = merged_items[:effective_target] if effective_target > 0 else []
        else:
            final_items = await ScriptGenerationService._refine_full_script(
                merged_items,
                drama_name,
                plot_analysis,
                None,
                effective_target,
            )
        data = {"items": final_items}
        validated = validate_script_items(data)
        return cast(Dict[str, Any], validated)

    # @staticmethod
    # async def _generate_script_json_simple(
    #     drama_name: str,
    #     plot_analysis: str,
    #     subtitle_content: str,
    #     project_id: Optional[str] = None,
    #     target_items_count: Optional[int] = None,
    # ) -> Dict[str, Any]:
    #     """(æ—§ç‰ˆé€»è¾‘) ç›´æ¥è°ƒç”¨æç¤ºè¯æ¨¡å—ç”Ÿæˆ"""
    #     default_key = ScriptGenerationService._default_prompt_key_for_project(project_id)
    #     key = ScriptGenerationService._resolve_prompt_key(project_id, default_key)
    #     variables = {
    #         "drama_name": drama_name,
    #         "plot_analysis": plot_analysis,
    #         "subtitle_content": subtitle_content,
    #     }
    #     try:
    #         messages_dicts = prompt_manager.build_chat_messages(key, variables)
    #     except KeyError:
    #         try:
    #             cat = (key.split(":", 1)[0] if ":" in key else "short_drama_narration")
    #             if cat == "movie_narration":
    #                 from modules.prompts.movie_narration import register_prompts
    #             else:
    #                 from modules.prompts.short_drama_narration import register_prompts
    #             register_prompts()
    #             messages_dicts = prompt_manager.build_chat_messages(key, variables)
    #         except Exception:
    #             key = default_key
    #             messages_dicts = prompt_manager.build_chat_messages(key, variables)
    #     messages = [ChatMessage(role=m["role"], content=m["content"]) for m in messages_dicts]
    #     if target_items_count and int(target_items_count) > 0:
    #         n = int(target_items_count)
    #         messages.insert(
    #             0,
    #             ChatMessage(
    #                 role="system",
    #                 content=(
    #                     f"ä½ å¿…é¡»ä»…è¾“å‡ºä¸€ä¸ªJSONå¯¹è±¡ï¼Œé”®ä¸º'items'ã€‚"
    #                     f"itemsæ•°ç»„é•¿åº¦å¿…é¡»ä¸¥æ ¼ç­‰äº{n}ï¼Œä¸èƒ½å¤šä¸èƒ½å°‘ã€‚"
    #                     f"æ¯æ¡å¿…é¡»åŒ…å«'_id','timestamp','picture','narration','OST'ã€‚"
    #                     f"ä¸å¾—è¾“å‡ºé™¤JSONä»¥å¤–çš„ä»»ä½•æ–‡å­—ã€‚"
    #                 ),
    #             ),
    #         )
    #     resp = await ai_service.send_chat(messages, response_format={"type": "json_object"})
    #     raw_text = resp.content

    #     # æ¸…æ´—ä¸æ ¡éªŒ
    #     data, raw_json = sanitize_json_text_to_dict(raw_text)
    #     validated = validate_script_items(data)
    #     return cast(Dict[str, Any], validated)

    @staticmethod
    def to_video_script(data: Dict[str, Any], total_duration: float) -> Dict[str, Any]:
        """
        å°†æ¨¡å‹çš„ items JSON è½¬æ¢ä¸ºå‰ç«¯ VideoScript ç»“æ„ï¼š
        { version, total_duration, segments: [{id, start_time, end_time, text, subtitle?}], metadata }
        """
        items = data.get("items", [])
        segments: List[Dict[str, Any]] = []
        for it in items:
            start_s, end_s = _parse_timestamp_pair(str(it.get("timestamp")))
            text = str(it.get("narration", "")).strip()
            seg = {
                "id": str(it.get("_id", len(segments) + 1)),
                "start_time": float(start_s),
                "end_time": float(end_s),
                "text": text,
            }
            # é™„å¸¦å¯ç”¨ä¿¡æ¯
            pic = it.get("picture")
            if pic:
                seg["subtitle"] = str(pic)
            segments.append(seg)

        now = datetime.now()
        generated_time = now.isoformat()
        version = f"{now.strftime('%Y%m%d%H%M%S')}"
        return {
            "ç”Ÿæˆæ—¶é—´": generated_time,
            'æ¡æ•°': len(segments),
            "version": version,
            "total_duration": float(total_duration or 0.0),
            "segments": segments,
            "metadata": {
                "created_at": generated_time,
            },
        }
